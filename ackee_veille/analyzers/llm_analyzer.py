"""
LLM Analyzer - Utilise l'API Anthropic Claude pour analyser et synth√©tiser la veille
"""
import os
import json
from typing import List, Dict, Any
from datetime import datetime
from anthropic import Anthropic
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LLMAnalyzer:
    """Analyseur utilisant Claude pour synth√©tiser la veille"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")

        self.client = Anthropic(api_key=self.api_key)
        self.model = config.get('llm', {}).get('model', 'claude-sonnet-4-5-20250929')
        self.max_tokens = config.get('llm', {}).get('max_tokens', 8000)
        self.temperature = config.get('llm', {}).get('temperature', 0.3)

    def analyze(self, raw_data: List[Dict[str, Any]], start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """
        Analyse les donn√©es brutes et g√©n√®re la synth√®se structur√©e

        Args:
            raw_data: Liste des articles/infos collect√©s
            start_date: Date de d√©but de la p√©riode
            end_date: Date de fin de la p√©riode

        Returns:
            Dictionnaire structur√© avec toutes les sections de la veille
        """
        logger.info(f"Starting LLM analysis of {len(raw_data)} items...")

        # Pr√©pare le contexte pour Claude
        context = self._prepare_context(raw_data, start_date, end_date)

        # G√©n√®re la synth√®se via Claude
        synthesis = self._generate_synthesis(context, start_date, end_date)

        logger.info("LLM analysis completed")
        return synthesis

    def _prepare_context(self, raw_data: List[Dict[str, Any]], start_date: datetime, end_date: datetime) -> str:
        """Pr√©pare le contexte des donn√©es pour Claude"""

        # Groupe les donn√©es par source
        grouped_data = {}
        for item in raw_data:
            source = item.get('source', 'Other')
            if source not in grouped_data:
                grouped_data[source] = []
            grouped_data[source].append(item)

        # Format le contexte
        context = f"""# DONN√âES COLLECT√âES POUR LA VEILLE ACKEE
P√©riode: {start_date.strftime('%d/%m/%Y')} ‚Üí {end_date.strftime('%d/%m/%Y')}
Total items: {len(raw_data)}

## DONN√âES PAR SOURCE

"""
        for source, items in grouped_data.items():
            context += f"### {source} ({len(items)} items)\n\n"
            for item in items[:20]:  # Limite √† 20 items par source pour √©viter de d√©passer la limite
                context += f"- **{item.get('title', 'No title')}**\n"
                context += f"  Date: {item.get('date', 'N/A')}\n"
                context += f"  URL: {item.get('url', 'N/A')}\n"
                context += f"  Summary: {item.get('summary', 'N/A')[:200]}...\n\n"

        return context

    def _generate_synthesis(self, context: str, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """G√©n√®re la synth√®se via l'API Claude"""

        # Charge le prompt de veille original
        prompt = self._build_analysis_prompt(context, start_date, end_date)

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # Parse la r√©ponse de Claude
            synthesis_text = response.content[0].text

            # Structure la r√©ponse
            synthesis = {
                "metadata": {
                    "period_start": start_date.isoformat(),
                    "period_end": end_date.isoformat(),
                    "generated_at": datetime.now().isoformat(),
                    "model": self.model,
                    "total_items_analyzed": len(context.split('\n'))
                },
                "synthesis": synthesis_text,
                "raw_response": synthesis_text
            }

            return synthesis

        except Exception as e:
            logger.error(f"Error calling Anthropic API: {str(e)}")
            raise

    def _build_analysis_prompt(self, context: str, start_date: datetime, end_date: datetime) -> str:
        """Construit le prompt d'analyse pour Claude"""

        week_number = start_date.isocalendar()[1]
        year = start_date.year

        prompt = f"""Tu es un analyste strat√©gique sp√©cialis√© en fintech et remittances pour Ackee Financial Services.

# CONTEXTE ACKEE
Ackee d√©veloppe une plateforme blockchain de transferts d'argent pour la diaspora africaine en Europe avec 0,5% de frais.
- Corridors: France/UK/EU ‚Üí Togo/B√©nin/C√¥te d'Ivoire/UEMOA
- Concurrents: Wave, Wise, Remitly, WorldRemit, Revolut, n√©obanques diaspora
- Stade: D√©veloppement produit, 13 co-fondateurs

# P√âRIODE ANALYS√âE
Semaine {week_number}/{year} : {start_date.strftime('%d/%m/%Y')} ‚Üí {end_date.strftime('%d/%m/%Y')}

# DONN√âES COLLECT√âES
{context}

# TA MISSION
Analyse ces donn√©es et g√©n√®re un rapport de veille structur√© selon les 6 axes suivants. IMPORTANT: Pour chaque information, tu DOIS inclure le lien source (URL) extrait des donn√©es.

## AXE 1: CONCURRENCE & ACTEURS üéØ
Identifie les mouvements strat√©giques (lev√©es de fonds, acquisitions, partenariats, expansion, pricing, nouveaux produits).
Pour chaque info, indique:
- Priorit√© [P0/P1/P2]
- Nom acteur + Type mouvement
- Date
- R√©sum√© (2-3 lignes)
- Implication pour Ackee
- **Source (URL compl√®te)**

## AXE 2: R√âGULATION & COMPLIANCE ‚öñÔ∏è
Identifie nouvelles r√©gulations, licences, sanctions, sandboxes, exigences AML/KYC.
Format identique avec impact timeline et action Ackee.

## AXE 3: TECHNOLOGIE & INFRASTRUCTURE ‚öôÔ∏è
Innovations blockchain, partenariats tech, nouveaux rails, cybers√©curit√©, standards.
Indique si c'est une opportunit√© ou menace pour Ackee.

## AXE 4: MARCH√â & TENDANCES üìä
Reports institutionnels, √©tudes march√©, pricing, consumer insights.
Liste les key findings et insights pour Ackee.

## AXE 5: √âCOSYST√àME & PARTENAIRES ü§ù
Nouveaux partenariats BaaS/fintechs, VCs activity, incubateurs, M&A.
Indique les opportunit√©s de partenariat pour Ackee.

## AXE 6: NOUVEAUX ENTRANTS üÜï
D√©tecte les nouveaux acteurs (funding, sandboxes, accelerators).
Pour chaque: segment, corridor, stade, funding, team, diff√©renciateur, action sugg√©r√©e.

## SIGNAUX FAIBLES üì°
2-3 tendances √©mergentes √† surveiller avec implications potentielles √† 6-12 mois.

## RECOMMANDATIONS üí°
1-2 actions strat√©giques bas√©es sur cette veille.

## QUICK WINS ‚ö°
1-3 actions concr√®tes r√©alisables en <7 jours avec deadlines.

# FORMAT DE SORTIE
G√©n√®re un rapport structur√© en Markdown, en fran√ßais, avec:
- Dashboard semaine (tableau avec m√©triques)
- Les 6 axes avec scoring P0/P1/P2
- Signaux faibles
- Recommandations
- Quick wins

CRITIQUE: Chaque information DOIT avoir son URL source extraite des donn√©es fournies.
Focus sur l'actionabilit√©: "Et alors, pour Ackee?"
Prioriser qualit√© > quantit√©.
"""

        return prompt

    def extract_critical_alerts(self, synthesis: Dict[str, Any]) -> List[str]:
        """Extrait les alertes critiques (P0) de la synth√®se"""
        # Cette fonction pourrait utiliser un second appel √† Claude pour extraire uniquement les P0
        # Pour l'instant, on retourne une liste vide
        return []
